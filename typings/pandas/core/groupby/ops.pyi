"""
This type stub file was generated by pyright.
"""

import numpy as np
from typing import Callable, Generic, TYPE_CHECKING, final
from pandas._typing import ArrayLike, AxisInt, NDFrameT, Shape, npt
from pandas.util._decorators import cache_readonly
from pandas.core.frame import DataFrame
from pandas.core.groupby import grouper
from pandas.core.indexes.api import Index
from pandas.core.series import Series
from collections.abc import Hashable, Iterator, Sequence
from pandas.core.generic import NDFrame

"""
Provide classes to perform the groupby aggregate operations.

These are not exposed to the user and provide implementations of the grouping
operations, primarily in cython. These classes (BaseGrouper and BinGrouper)
are contained *in* the SeriesGroupBy and DataFrameGroupBy objects.
"""
if TYPE_CHECKING:
    ...
def check_result_array(obj, dtype) -> None:
    ...

def extract_result(res):
    """
    Extract the result object, it might be a 0-dim ndarray
    or a len-1 0-dim, or a scalar
    """
    ...

class WrappedCythonOp:
    """
    Dispatch logic for functions defined in _libs.groupby

    Parameters
    ----------
    kind: str
        Whether the operation is an aggregate or transform.
    how: str
        Operation name, e.g. "mean".
    has_dropped_na: bool
        True precisely when dropna=True and the grouper contains a null value.
    """
    cast_blocklist = ...
    def __init__(self, kind: str, how: str, has_dropped_na: bool) -> None:
        ...
    
    _CYTHON_FUNCTIONS: dict[str, dict] = ...
    _cython_arity = ...
    @classmethod
    def get_kind_from_how(cls, how: str) -> str:
        ...
    
    @final
    def cython_operation(self, *, values: ArrayLike, axis: AxisInt, min_count: int = ..., comp_ids: np.ndarray, ngroups: int, **kwargs) -> ArrayLike:
        """
        Call our cython function, with appropriate pre- and post- processing.
        """
        ...
    


class BaseGrouper:
    """
    This is an internal Grouper class, which actually holds
    the generated groups

    Parameters
    ----------
    axis : Index
    groupings : Sequence[Grouping]
        all the grouping instances to handle in this grouper
        for example for grouper list to groupby, need to pass the list
    sort : bool, default True
        whether this grouper will give sorted result or not

    """
    axis: Index
    def __init__(self, axis: Index, groupings: Sequence[grouper.Grouping], sort: bool = ..., dropna: bool = ...) -> None:
        ...
    
    @property
    def groupings(self) -> list[grouper.Grouping]:
        ...
    
    @property
    def shape(self) -> Shape:
        ...
    
    def __iter__(self) -> Iterator[Hashable]:
        ...
    
    @property
    def nkeys(self) -> int:
        ...
    
    def get_iterator(self, data: NDFrameT, axis: AxisInt = ...) -> Iterator[tuple[Hashable, NDFrameT]]:
        """
        Groupby iterator

        Returns
        -------
        Generator yielding sequence of (name, subsetted object)
        for each group
        """
        ...
    
    @final
    @cache_readonly
    def group_keys_seq(self): # -> Index | list[tuple[Any, ...]]:
        ...
    
    @cache_readonly
    def indices(self) -> dict[Hashable, npt.NDArray[np.intp]]:
        """dict {group name -> group indices}"""
        ...
    
    @final
    def result_ilocs(self) -> npt.NDArray[np.intp]:
        """
        Get the original integer locations of result_index in the input.
        """
        ...
    
    @final
    @property
    def codes(self) -> list[npt.NDArray[np.signedinteger]]:
        ...
    
    @property
    def levels(self) -> list[Index]:
        ...
    
    @property
    def names(self) -> list[Hashable]:
        ...
    
    @final
    def size(self) -> Series:
        """
        Compute group sizes.
        """
        ...
    
    @cache_readonly
    def groups(self) -> dict[Hashable, np.ndarray]:
        """dict {group name -> group labels}"""
        ...
    
    @final
    @cache_readonly
    def is_monotonic(self) -> bool:
        ...
    
    @final
    @cache_readonly
    def has_dropped_na(self) -> bool:
        """
        Whether grouper has null value(s) that are dropped.
        """
        ...
    
    @cache_readonly
    def group_info(self) -> tuple[npt.NDArray[np.intp], npt.NDArray[np.intp], int]:
        ...
    
    @cache_readonly
    def codes_info(self) -> npt.NDArray[np.intp]:
        ...
    
    @final
    @cache_readonly
    def ngroups(self) -> int:
        ...
    
    @property
    def reconstructed_codes(self) -> list[npt.NDArray[np.intp]]:
        ...
    
    @cache_readonly
    def result_index(self) -> Index:
        ...
    
    @final
    def get_group_levels(self) -> list[ArrayLike]:
        ...
    
    @final
    def agg_series(self, obj: Series, func: Callable, preserve_dtype: bool = ...) -> ArrayLike:
        """
        Parameters
        ----------
        obj : Series
        func : function taking a Series and returning a scalar-like
        preserve_dtype : bool
            Whether the aggregation is known to be dtype-preserving.

        Returns
        -------
        np.ndarray or ExtensionArray
        """
        ...
    
    @final
    def apply_groupwise(self, f: Callable, data: DataFrame | Series, axis: AxisInt = ...) -> tuple[list, bool]:
        ...
    


class BinGrouper(BaseGrouper):
    """
    This is an internal Grouper class

    Parameters
    ----------
    bins : the split index of binlabels to group the item of axis
    binlabels : the label list
    indexer : np.ndarray[np.intp], optional
        the indexer created by Grouper
        some groupers (TimeGrouper) will sort its axis and its
        group_info is also sorted, so need the indexer to reorder

    Examples
    --------
    bins: [2, 4, 6, 8, 10]
    binlabels: DatetimeIndex(['2005-01-01', '2005-01-03',
        '2005-01-05', '2005-01-07', '2005-01-09'],
        dtype='datetime64[ns]', freq='2D')

    the group_info, which contains the label of each item in grouped
    axis, the index of label in label list, group number, is

    (array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4]), array([0, 1, 2, 3, 4]), 5)

    means that, the grouped axis has 10 items, can be grouped into 5
    labels, the first and second items belong to the first label, the
    third and forth items belong to the second label, and so on

    """
    bins: npt.NDArray[np.int64]
    binlabels: Index
    def __init__(self, bins, binlabels, indexer=...) -> None:
        ...
    
    @cache_readonly
    def groups(self): # -> dict[Any, Any]:
        """dict {group name -> group labels}"""
        ...
    
    @property
    def nkeys(self) -> int:
        ...
    
    @cache_readonly
    def codes_info(self) -> npt.NDArray[np.intp]:
        ...
    
    def get_iterator(self, data: NDFrame, axis: AxisInt = ...): # -> Generator[tuple[Any, Any] | tuple[Any | Index, Any], Any, None]:
        """
        Groupby iterator

        Returns
        -------
        Generator yielding sequence of (name, subsetted object)
        for each group
        """
        ...
    
    @cache_readonly
    def indices(self): # -> defaultdict[Any, list[Any]]:
        ...
    
    @cache_readonly
    def group_info(self) -> tuple[npt.NDArray[np.intp], npt.NDArray[np.intp], int]:
        ...
    
    @cache_readonly
    def reconstructed_codes(self) -> list[np.ndarray]:
        ...
    
    @cache_readonly
    def result_index(self) -> Index:
        ...
    
    @property
    def levels(self) -> list[Index]:
        ...
    
    @property
    def names(self) -> list[Hashable]:
        ...
    
    @property
    def groupings(self) -> list[grouper.Grouping]:
        ...
    


class DataSplitter(Generic[NDFrameT]):
    def __init__(self, data: NDFrameT, labels: npt.NDArray[np.intp], ngroups: int, *, sort_idx: npt.NDArray[np.intp], sorted_ids: npt.NDArray[np.intp], axis: AxisInt = ...) -> None:
        ...
    
    def __iter__(self) -> Iterator:
        ...
    


class SeriesSplitter(DataSplitter):
    ...


class FrameSplitter(DataSplitter):
    ...


